{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker related information\n",
    "\n",
    "https://github.com/jupyter/docker-stacks\n",
    "\n",
    "localnotebookpath='/Users/maheshgoud/Documents/Git_Modules/gh/sandbox/'\n",
    "\n",
    "localdatapath='/Users/maheshgoud/Downloads/data/'\n",
    "\n",
    "#allsparkpackagenames='org.apache.spark:spark-avro_2.11:2.4.0,com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.2'\n",
    "\n",
    "docker run -it --rm -p 8889:8888 -v $localnotebookpath:/home/jovyan -v $localdatapath:/home/jovyan/data -e JUPYTER_ENABLE_LAB=yes -e SPARK_OPTS='--packages org.apache.spark:spark-avro_2.11:2.4.0,com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.2' \\\n",
    "-e PYSPARK_SUBMIT_ARGS='--packages com.databricks:spark-avro_2.10:2.0.1 pyspark-shell' jupyter/all-spark-notebook:7d427e7a4dde start-notebook.sh --NotebookApp.token=''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful code snippets\n",
    "\n",
    "- https://www.programcreek.com/scala/org.apache.spark.SparkConf (code snippets)\n",
    "- https://gist.github.com/eddies/f37d696567f15b33029277ee9084c4a0 (s3 access, packages related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scala.collection.Seq\n",
    "import sys.process._\n",
    "\n",
    "// import spark.implicits._\n",
    "// import org.apache.spark.sql.Row\n",
    "\n",
    "println(\"Spark version: \"+sc.version)\n",
    "println(\"Scala version: \"+util.Properties.versionString)\n",
    "\"python --version\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Declare some dummy dataframe\n",
    "\n",
    "val df = Seq(\n",
    "      (1, \"foo\"),\n",
    "      (2, \"barrio\"),\n",
    "      (3, \"gitten\"),\n",
    "      (4, \"baa\")).toDF(\"id\", \"words\")\n",
    "\n",
    "// val someData = Seq(\n",
    "//   Row(8, \"bat\"),\n",
    "//   Row(64, \"mouse\"),\n",
    "//   Row(-27, \"horse\")\n",
    "// )\n",
    "\n",
    "// val someSchema = List(\n",
    "//   StructField(\"number\", IntegerType, true),\n",
    "//   StructField(\"word\", StringType, true)\n",
    "// )\n",
    "\n",
    "// val someDF = spark.createDataFrame(\n",
    "//   spark.sparkContext.parallelize(someData),\n",
    "//   StructType(someSchema)\n",
    "// )\n",
    "\n",
    "// dictionary Set of words to check \n",
    "val d = Set(\"foo\",\"bar\",\"baa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"isValid\", $\"words\".isInCollection(d)).show()\n",
    "df.filter($\"words\".isInCollection(d)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Read avro data from s3\n",
    "// https://github.com/julianpeeters/avro-spark-examples/blob/master/src/main/scala/AvroSparkScala.scala\n",
    "\n",
    "// import org.apache.avro.generic.GenericRecord\n",
    "// import org.apache.avro.mapred.AvroKey\n",
    "// import org.apache.avro.mapreduce.AvroKeyInputFormat\n",
    "// import org.apache.hadoop.io.NullWritable\n",
    "// val rdd = sc.newAPIHadoopFile(local_path,\n",
    "//   classOf[AvroKeyInputFormat[GenericRecord]],\n",
    "//   classOf[AvroKey[GenericRecord]],\n",
    "//   classOf[NullWritable]\n",
    "// )\n",
    "// rdd.collect()\n",
    "\n",
    "// s3a://key:secret@\n",
    "val local_path = \"./data/part.avro\"\n",
    "\n",
    "val conf = sc.hadoopConfiguration\n",
    "conf.set(\"fs.s3a.access.key\", \"\")\n",
    "conf.set(\"fs.s3a.secret.key\", \"\")\n",
    "\n",
    "val df = spark.read\n",
    "    .format(\"com.databricks.spark.avro\")\n",
    "    .load(local_path)\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
